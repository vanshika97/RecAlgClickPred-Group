{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python: 3.7.4 (default, Aug  9 2019, 18:34:13) [MSC v.1915 64 bit (AMD64)]\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import math\n",
    "import sklearn\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import xgboost as xgb\n",
    "from time import time\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import linear_model\n",
    "%config IPcompletor.greedy = True\n",
    "from sklearn.svm import LinearSVC, SVC\n",
    "print(\"Python: {}\".format(sys.version))\n",
    "from imblearn.over_sampling import SMOTE, SVMSMOTE, ADASYN\n",
    "from imblearn.under_sampling import NearMiss\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import f1_score, confusion_matrix, mean_squared_error,recall_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set = pd.read_csv(\"tcdml1920-rec-click-pred--training.csv\", index_col = 0,error_bad_lines=True)#385688\n",
    "test_set = pd.read_csv(\"tcdml1920-rec-click-pred--test.csv\", index_col = 0,error_bad_lines=False)#9146\n",
    "test_set.dropna(how=\"all\", inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NULL values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set.replace([\"\\\\N\", \"nA\", \"Not provided\", \"*unknown*\"], np.nan, inplace=True)\n",
    "test_set.replace([\"\\\\N\", \"nA\", \"Not provided\", \"*unknown*\"], np.nan, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = train_set[(train_set[\"set_clicked\"] == 1) | (train_set.time_recs_viewed.notnull())]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = temp.drop(columns = [\"time_recs_viewed\"])\n",
    "test_set = test_set.drop(columns = [\"time_recs_viewed\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in temp.select_dtypes(include=['object']):\n",
    "    target = temp.groupby(i)[\"set_clicked\"].agg(pd.Series.mean)\n",
    "    temp[i] = temp[i].map(target)\n",
    "    test_set[i] = test_set[i].map(target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp[temp.columns]=temp[temp.columns].fillna(temp.mean().iloc[0])\n",
    "target = temp.pop(\"set_clicked\")\n",
    "test_set[test_set.columns]=test_set[test_set.columns].fillna(test_set.mean().iloc[0])\n",
    "pp= test_set.pop(\"set_clicked\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "user_id                             0\n",
       "session_id                          0\n",
       "query_identifier                    0\n",
       "query_word_count                    0\n",
       "query_char_count                    0\n",
       "query_detected_language             0\n",
       "query_document_id                   0\n",
       "document_language_provided          0\n",
       "year_published                      0\n",
       "number_of_authors                   0\n",
       "abstract_word_count                 0\n",
       "abstract_char_count                 0\n",
       "abstract_detected_language          0\n",
       "first_author_id                     0\n",
       "num_pubs_by_first_author            0\n",
       "organization_id                     0\n",
       "application_type                    0\n",
       "item_type                           0\n",
       "request_received                    0\n",
       "hour_request_received               0\n",
       "response_delivered                  0\n",
       "rec_processing_time                 0\n",
       "app_version                         0\n",
       "app_lang                            0\n",
       "user_os                             0\n",
       "user_os_version                     0\n",
       "user_java_version                   0\n",
       "user_timezone                       0\n",
       "country_by_ip                       0\n",
       "timezone_by_ip                      0\n",
       "local_time_of_request               0\n",
       "local_hour_of_request               0\n",
       "number_of_recs_in_set               0\n",
       "recommendation_algorithm_id_used    0\n",
       "algorithm_class                     0\n",
       "cbf_parser                          0\n",
       "search_title                        0\n",
       "search_keywords                     0\n",
       "search_abstract                     0\n",
       "time_recs_recieved                  0\n",
       "time_recs_displayed                 0\n",
       "clicks                              0\n",
       "ctr                                 0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\agarwalv\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "C:\\Users\\agarwalv\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\agarwalv\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[   0 9065]\n",
      " [   1   80]]\n",
      "[[   0 9145]]\n",
      "[[   0 9131]\n",
      " [   1   14]]\n",
      "[[   1 9145]]\n"
     ]
    }
   ],
   "source": [
    "model1 = RandomForestClassifier()\n",
    "model2 = LogisticRegression()\n",
    "model3 = SVC()\n",
    "model4 = DecisionTreeClassifier()\n",
    "\n",
    "model1.fit(temp, target)\n",
    "model2.fit(temp, target)\n",
    "model3.fit(temp, target)\n",
    "model4.fit(temp, target)\n",
    "\n",
    "y_pred1 = model1.predict(test_set)\n",
    "y_pred2 = model2.predict(test_set)\n",
    "y_pred3 = model3.predict(test_set)\n",
    "y_pred4 = model4.predict(test_set)\n",
    "\n",
    "print(np.array(np.unique(y_pred1, return_counts=True)).T)\n",
    "print(np.array(np.unique(y_pred2, return_counts=True)).T)\n",
    "print(np.array(np.unique(y_pred3, return_counts=True)).T)\n",
    "print(np.array(np.unique(y_pred4, return_counts=True)).T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "submit[\"set_clicked\"] = y_pred1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_1cbf = train_set[(train_set.organization_id == 1) & (train_set.algorithm_class == 'content_based_filtering')]\n",
    "train_1 = train_set[(train_set.organization_id == 1) & (train_set.algorithm_class != 'content_based_filtering')]\n",
    "train_2cbf = train_set[(train_set.organization_id != 1) & (train_set.algorithm_class == 'content_based_filtering')]\n",
    "train_2 = train_set[(train_set.organization_id != 1) & (train_set.algorithm_class != 'content_based_filtering')]\n",
    "train_4 = train_set[train_set.organization_id == 4]\n",
    "train_8 = train_set[train_set.organization_id == 8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_1cbf = test_set[(test_set.organization_id == 1) & (test_set.algorithm_class == 'content_based_filtering')]\n",
    "test_1 = test_set[(test_set.organization_id == 1) & (test_set.algorithm_class != 'content_based_filtering')]\n",
    "test_2cbf = test_set[(test_set.organization_id != 1) & (test_set.algorithm_class == 'content_based_filtering')]\n",
    "test_2 = test_set[(test_set.organization_id != 1) & (test_set.algorithm_class != 'content_based_filtering')]\n",
    "test_4 = test_set[test_set.organization_id == 4]\n",
    "test_8 = test_set[test_set.organization_id == 8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_1 = train_1.drop(columns =['algorithm_class','app_lang','app_version','application_type','cbf_parser','hour_request_received','item_type', 'local_time_of_request','number_of_recs_in_set','organization_id','query_char_count','query_detected_language','query_identifier','request_received','response_delivered','search_abstract','search_keywords','search_title','timezone_by_ip','user_id', 'session_id','abstract_detected_language','rec_processing_time', 'time_recs_recieved', 'time_recs_displayed'])\n",
    "train_1cbf = train_1cbf.drop(columns =['algorithm_class','app_lang','app_version','application_type','hour_request_received','item_type', 'local_time_of_request','number_of_recs_in_set','organization_id','query_char_count','query_detected_language','query_identifier','request_received','response_delivered','search_abstract','search_keywords','search_title','timezone_by_ip','user_id', 'session_id','abstract_detected_language','rec_processing_time', 'time_recs_recieved', 'time_recs_displayed'])\n",
    "test_1 = test_1.drop(columns =['algorithm_class','app_lang','app_version','application_type','cbf_parser','hour_request_received','item_type', 'local_time_of_request','number_of_recs_in_set','organization_id','query_char_count','query_detected_language','query_identifier','request_received','response_delivered','search_abstract','search_keywords','search_title','timezone_by_ip','user_id', 'session_id','abstract_detected_language','rec_processing_time', 'time_recs_recieved', 'time_recs_displayed'])\n",
    "test_1cbf = test_1cbf.drop(columns =['algorithm_class','app_lang','app_version','application_type','hour_request_received','item_type', 'local_time_of_request','number_of_recs_in_set','organization_id','query_char_count','query_detected_language','query_identifier','request_received','response_delivered','search_abstract','search_keywords','search_title','timezone_by_ip','user_id', 'session_id','abstract_detected_language','rec_processing_time', 'time_recs_recieved', 'time_recs_displayed'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_2 = train_2.drop(columns =['abstract_char_count', 'algorithm_class','app_lang','app_version','application_type','hour_request_received','local_time_of_request','number_of_recs_in_set','organization_id','query_char_count','query_detected_language','query_identifier','request_received','response_delivered','search_abstract','search_keywords','search_title','timezone_by_ip','user_id', 'session_id','abstract_detected_language','rec_processing_time', 'time_recs_recieved', 'time_recs_displayed'])\n",
    "train_2cbf = train_2cbf.drop(columns =['abstract_word_count', 'algorithm_class','app_lang','app_version','application_type','hour_request_received','local_time_of_request','number_of_recs_in_set','organization_id','query_char_count','query_detected_language','query_identifier','request_received','response_delivered','search_abstract','search_keywords','search_title','timezone_by_ip','user_id', 'session_id','abstract_detected_language','rec_processing_time', 'time_recs_recieved', 'time_recs_displayed'])\n",
    "test_2 = test_2.drop(columns =['abstract_char_count', 'algorithm_class','app_lang','app_version','application_type','hour_request_received','local_time_of_request','number_of_recs_in_set','organization_id','query_char_count','query_detected_language','query_identifier','request_received','response_delivered','search_abstract','search_keywords','search_title','timezone_by_ip','user_id', 'session_id','abstract_detected_language','rec_processing_time', 'time_recs_recieved', 'time_recs_displayed'])\n",
    "test_2cbf = test_2cbf.drop(columns =['abstract_word_count', 'algorithm_class','app_lang','app_version','application_type','hour_request_received','local_time_of_request','number_of_recs_in_set','organization_id','query_char_count','query_detected_language','query_identifier','request_received','response_delivered','search_abstract','search_keywords','search_title','timezone_by_ip','user_id', 'session_id','abstract_detected_language','rec_processing_time', 'time_recs_recieved', 'time_recs_displayed'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_1.dropna(thresh= train_1[train_1[\"set_clicked\"] == 0].shape[0]*0.4, axis=1, inplace = True)\n",
    "train_2.dropna(thresh= train_2.shape[0]*0.4, axis=1, inplace = True)\n",
    "train_1cbf.dropna(thresh= train_1cbf.shape[0]*0.4, axis=1, inplace = True)\n",
    "train_2cbf.dropna(thresh= train_2cbf.shape[0]*0.4, axis=1, inplace = True)\n",
    "train_4.dropna(thresh= train_4.shape[0]*0.4, axis=1, inplace = True)\n",
    "train_8.dropna(thresh= train_8.shape[0]*0.4, axis=1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(train_1.shape)\n",
    "print(train_2.shape)\n",
    "print(train_1cbf.shape)\n",
    "print(train_2cbf.shape)\n",
    "print(train_4.shape)\n",
    "print(train_8.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_1 = test_1[list(train_1.columns)]\n",
    "test_2 = test_2[list(train_2.columns)]\n",
    "test_1cbf = test_1cbf[list(train_1cbf.columns)]\n",
    "test_2cbf = test_2cbf[list(train_2cbf.columns)]\n",
    "test_4 = test_4[list(train_4.columns)]\n",
    "test_8 = test_8[list(train_8.columns)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_1[train_1.columns]=train_1[train_1.columns].fillna(train_1.mode().iloc[0])\n",
    "train_2[train_2.columns]=train_2[train_2.columns].fillna(train_2.mode().iloc[0])\n",
    "train_1cbf[train_1cbf.columns]=train_1cbf[train_1cbf.columns].fillna(train_1cbf.mode().iloc[0])\n",
    "train_2cbf[train_2cbf.columns]=train_2cbf[train_2cbf.columns].fillna(train_2cbf.mode().iloc[0])\n",
    "train_4[train_4.columns]=train_4[train_4.columns].fillna(train_4.mode().iloc[0])\n",
    "train_8[train_8.columns]=train_8[train_8.columns].fillna(train_8.mode().iloc[0])\n",
    "test_1[test_1.columns]=test_1[test_1.columns].fillna(train_1.mode().iloc[0])\n",
    "test_1cbf[test_1cbf.columns]=test_1cbf[test_1cbf.columns].fillna(train_1cbf.mode().iloc[0])\n",
    "test_2[test_2.columns]=test_2[test_2.columns].fillna(train_2.mode().iloc[0])\n",
    "test_2cbf[test_2cbf.columns]=test_2cbf[test_2cbf.columns].fillna(train_2cbf.mode().iloc[0])\n",
    "test_4[test_4.columns]=test_4[test_4.columns].fillna(train_4.mode().iloc[0])\n",
    "test_8[test_8.columns]=test_8[test_8.columns].fillna(train_8.mode().iloc[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### To Numeric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_cols_8 = [\"abstract_word_count\",\"query_word_count\",\"query_char_count\",\"query_document_id\",\"abstract_char_count\",\"hour_request_received\",\"local_hour_of_request\",\"recommendation_algorithm_id_used\",\"clicks\"]\n",
    "numeric_cols_4 = [\"query_word_count\",\"query_char_count\",\"hour_request_received\",\"recommendation_algorithm_id_used\",\"clicks\"]\n",
    "numeric_cols_1 = [\"query_word_count\",\"local_hour_of_request\",\"recommendation_algorithm_id_used\"]\n",
    "numeric_cols_1cbf = [\"query_word_count\",\"local_hour_of_request\",\"recommendation_algorithm_id_used\"]\n",
    "numeric_cols_2 = [\"query_word_count\", \"query_document_id\", \"abstract_word_count\", \"local_hour_of_request\",\"recommendation_algorithm_id_used\",\"clicks\"]\n",
    "numeric_cols_2cbf = [\"query_word_count\", \"query_document_id\", \"local_hour_of_request\",\"recommendation_algorithm_id_used\",\"clicks\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in numeric_cols_1:\n",
    "    train_1[i] = pd.to_numeric(train_1[i], errors='coerce')\n",
    "    test_1[i] = pd.to_numeric(test_1[i], errors='coerce')\n",
    "for i in numeric_cols_4:\n",
    "    train_4[i] = pd.to_numeric(train_4[i], errors='coerce')\n",
    "    test_4[i] = pd.to_numeric(test_4[i], errors='coerce')\n",
    "for i in numeric_cols_8:\n",
    "    train_8[i] = pd.to_numeric(train_8[i], errors='coerce')\n",
    "    test_8[i] = pd.to_numeric(test_8[i], errors='coerce')\n",
    "for i in numeric_cols_1cbf:\n",
    "    train_1cbf[i] = pd.to_numeric(train_1cbf[i], errors='coerce')\n",
    "    test_1cbf[i] = pd.to_numeric(test_1cbf[i], errors='coerce')\n",
    "for i in numeric_cols_2:\n",
    "    train_2[i] = pd.to_numeric(train_2[i], errors='coerce')\n",
    "    test_2[i] = pd.to_numeric(test_2[i], errors='coerce')\n",
    "for i in numeric_cols_2cbf:\n",
    "    train_2cbf[i] = pd.to_numeric(train_2cbf[i], errors='coerce')\n",
    "    test_2cbf[i] = pd.to_numeric(test_2cbf[i], errors='coerce')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_1.index = test_1.index.astype(\"int\")\n",
    "test_1cbf.index = test_1cbf.index.astype(\"int\")\n",
    "test_2.index = test_2.index.astype(\"int\")\n",
    "test_2cbf.index = test_2cbf.index.astype(\"int\")\n",
    "test_4.index = test_4.index.astype(\"int\")\n",
    "test_8.index = test_8.index.astype(\"int\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Encoding\n",
    "- One hot\n",
    "- Target\n",
    "- Label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_1.dropna(how=\"all\", inplace = True)\n",
    "test_1cbf.dropna(how=\"all\", inplace = True)\n",
    "test_2.dropna(how=\"all\", inplace = True)\n",
    "test_2cbf.dropna(how=\"all\", inplace = True)\n",
    "test_4.dropna(how=\"all\", inplace = True)\n",
    "test_8.dropna(how=\"all\", inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in train_1.select_dtypes(include=['object']):\n",
    "    target = train_1.groupby(i)[\"set_clicked\"].agg(pd.Series.mean)\n",
    "    train_1[i] = train_1[i].map(target)\n",
    "    test_1[i] = test_1[i].map(target)\n",
    "for i in train_1cbf.select_dtypes(include=['object']):\n",
    "    target = train_1cbf.groupby(i)[\"set_clicked\"].agg(pd.Series.mean)\n",
    "    train_1cbf[i] = train_1cbf[i].map(target)\n",
    "    test_1cbf[i] = test_1cbf[i].map(target)\n",
    "for i in train_2.select_dtypes(include=['object']):\n",
    "    target = train_2.groupby(i)[\"set_clicked\"].agg(pd.Series.mean)\n",
    "    train_2[i] = train_2[i].map(target)\n",
    "    test_2[i] = test_2[i].map(target)\n",
    "for i in train_2cbf.select_dtypes(include=['object']):\n",
    "    target = train_2cbf.groupby(i)[\"set_clicked\"].agg(pd.Series.mean)\n",
    "    train_2cbf[i] = train_2cbf[i].map(target)\n",
    "    test_2cbf[i] = test_2cbf[i].map(target)\n",
    "\n",
    "for i in train_4.select_dtypes(include=['object']):\n",
    "    target = train_4.groupby(i)[\"set_clicked\"].agg(pd.Series.mean)\n",
    "    train_4[i] = train_4[i].map(target)\n",
    "    test_4[i] = test_4[i].map(target)\n",
    "for i in train_8.select_dtypes(include=['object']):\n",
    "    target = train_8.groupby(i)[\"set_clicked\"].agg(pd.Series.mean)\n",
    "    train_8[i] = train_8[i].map(target)\n",
    "    test_8[i] = test_8[i].map(target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_1[test_1.columns]=test_1[test_1.columns].fillna(test_1.mean().iloc[0])\n",
    "test_1cbf[test_1cbf.columns]=test_1cbf[test_1cbf.columns].fillna(test_1cbf.mean().iloc[0])\n",
    "test_2[test_2.columns]=test_2[test_2.columns].fillna(test_2.mean().iloc[0])\n",
    "test_2cbf[test_2cbf.columns]=test_2cbf[test_2cbf.columns].fillna(test_2cbf.mean().iloc[0])\n",
    "test_4[test_4.columns]=test_4[test_4.columns].fillna(test_4.mean().iloc[0])\n",
    "test_8[test_8.columns]=test_8[test_8.columns].fillna(test_8.mean().iloc[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_1 = train_1.pop(\"set_clicked\")\n",
    "test_1.drop(columns=[\"set_clicked\"], inplace =True)\n",
    "print(\"Target: {}, Training: {}\".format(target_1.shape, train_1.shape))\n",
    "target_1cbf = train_1cbf.pop(\"set_clicked\")\n",
    "test_1cbf.drop(columns=[\"set_clicked\"], inplace =True)\n",
    "print(\"Target: {}, Training: {}\".format(target_1cbf.shape, train_1cbf.shape))\n",
    "target_2 = train_2.pop(\"set_clicked\")\n",
    "test_2.drop(columns=[\"set_clicked\"], inplace =True)\n",
    "print(\"Target: {}, Training: {}\".format(target_2.shape, train_2.shape))\n",
    "target_2cbf = train_2cbf.pop(\"set_clicked\")\n",
    "test_2cbf.drop(columns=[\"set_clicked\"], inplace =True)\n",
    "print(\"Target: {}, Training: {}\".format(target_2cbf.shape, train_2cbf.shape))\n",
    "target_4 = train_4.pop(\"set_clicked\")\n",
    "test_4.drop(columns=[\"set_clicked\"], inplace =True)\n",
    "print(\"Target: {}, Training: {}\".format(target_4.shape, train_4.shape))\n",
    "target_8 = train_8.pop(\"set_clicked\")\n",
    "test_8.drop(columns=[\"set_clicked\"], inplace =True)\n",
    "print(\"Target: {}, Training: {}\".format(target_8.shape, train_8.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SMOTE\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "smt = SVMSMOTE()\n",
    "# train_1, target_1 = smt.fit_sample(train_1, target_1)\n",
    "# train_4, target_4 = smt.fit_sample(train_4,target_4)\n",
    "train_8, target_8 = smt.fit_sample(train_8,target_8)\n",
    "\n",
    "smt = ADASYN()\n",
    "train_1, target_1 = smt.fit_sample(train_1, target_1)\n",
    "train_4, target_4 = smt.fit_sample(train_4,target_4)\n",
    "# train_8, target_8 = smt.fit_sample(train_8,target_8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NearMiss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "nr = NearMiss()\n",
    "# train_1, target_1 = nr.fit_sample(train_1, target_1)\n",
    "# train_4, target_4 = nr.fit_sample(train_4,target_4)\n",
    "# train_8, target_8 = nr.fit_sample(train_8,target_8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bagging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[   0 1379]]\n",
      "[[   0 3797]]\n",
      "[[   0 1308]]\n",
      "[[   0 2661]]\n",
      "[[   0 3029]]\n",
      "[[  0 940]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import BaggingClassifier\n",
    "clf1 = BaggingClassifier()\n",
    "clf4 = BaggingClassifier()\n",
    "clf8 = BaggingClassifier()\n",
    "clf1cbf = BaggingClassifier()\n",
    "clf2 = BaggingClassifier()\n",
    "clf2cbf = BaggingClassifier()\n",
    "clf1.fit(train_1, target_1)\n",
    "clf1cbf.fit(train_1cbf, target_1cbf)\n",
    "clf2.fit(train_2, target_2)\n",
    "clf2cbf.fit(train_2cbf, target_2cbf)\n",
    "clf4.fit(train_4, target_4)\n",
    "clf8.fit(train_8, target_8)\n",
    "y_pred1 = clf1.predict(test_1)\n",
    "y_pred1cbf = clf1cbf.predict(test_1cbf)\n",
    "y_pred2 = clf2.predict(test_2)\n",
    "y_pred2cbf = clf2cbf.predict(test_2cbf)\n",
    "y_pred4 = clf4.predict(test_4)\n",
    "y_pred8 = clf8.predict(test_8)\n",
    "print(np.array(np.unique(y_pred1, return_counts=True)).T)\n",
    "print(np.array(np.unique(y_pred1cbf, return_counts=True)).T)\n",
    "print(np.array(np.unique(y_pred2, return_counts=True)).T)\n",
    "print(np.array(np.unique(y_pred2cbf, return_counts=True)).T)\n",
    "print(np.array(np.unique(y_pred4, return_counts=True)).T)\n",
    "print(np.array(np.unique(y_pred8, return_counts=True)).T)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\agarwalv\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\agarwalv\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\agarwalv\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\agarwalv\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\agarwalv\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[   0 1379]]\n",
      "[[   0 3797]]\n",
      "[[   0 1308]]\n",
      "[[   0 2661]]\n",
      "[[   0 3029]]\n",
      "[[  0 940]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\agarwalv\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "clf1 = LogisticRegression()\n",
    "clf1cbf = LogisticRegression()\n",
    "clf2 = LogisticRegression()\n",
    "clf2cbf = LogisticRegression()\n",
    "clf4 = LogisticRegression()\n",
    "clf8 = LogisticRegression()\n",
    "clf1.fit(train_1, target_1)\n",
    "clf1cbf.fit(train_1cbf, target_1cbf)\n",
    "clf2.fit(train_2, target_2)\n",
    "clf2cbf.fit(train_2cbf, target_2cbf)\n",
    "clf4.fit(train_4, target_4)\n",
    "clf8.fit(train_8, target_8)\n",
    "y_pred1 = clf1.predict(test_1)\n",
    "y_pred1cbf = clf1cbf.predict(test_1cbf)\n",
    "y_pred2 = clf2.predict(test_2)\n",
    "y_pred2cbf = clf2cbf.predict(test_2cbf)\n",
    "y_pred4 = clf4.predict(test_4)\n",
    "y_pred8 = clf8.predict(test_8)\n",
    "print(np.array(np.unique(y_pred1, return_counts=True)).T)\n",
    "print(np.array(np.unique(y_pred1cbf, return_counts=True)).T)\n",
    "print(np.array(np.unique(y_pred2, return_counts=True)).T)\n",
    "print(np.array(np.unique(y_pred2cbf, return_counts=True)).T)\n",
    "print(np.array(np.unique(y_pred4, return_counts=True)).T)\n",
    "print(np.array(np.unique(y_pred8, return_counts=True)).T)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[   0 1379]]\n",
      "[[   0 3029]]\n",
      "[[  0 940]]\n"
     ]
    }
   ],
   "source": [
    "dt_1 = DecisionTreeClassifier()\n",
    "dt_4 = DecisionTreeClassifier()\n",
    "dt_8 = DecisionTreeClassifier()\n",
    "dt_1.fit(train_1, target_1)\n",
    "dt_4.fit(train_4, target_4)\n",
    "dt_8.fit(train_8, target_8)\n",
    "y_pred1 = dt_1.predict(test_1)\n",
    "y_pred4 = dt_4.predict(test_4)\n",
    "y_pred8 = dt_8.predict(test_8)\n",
    "\n",
    "print(np.array(np.unique(y_pred1, return_counts=True)).T)\n",
    "print(np.array(np.unique(y_pred4, return_counts=True)).T)\n",
    "print(np.array(np.unique(y_pred8, return_counts=True)).T)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\agarwalv\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "C:\\Users\\agarwalv\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "C:\\Users\\agarwalv\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "C:\\Users\\agarwalv\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "C:\\Users\\agarwalv\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[   0 1379]]\n",
      "[[   0 3797]]\n",
      "[[   0 1308]]\n",
      "[[   0 2661]]\n",
      "[[   0 3029]]\n",
      "[[  0 940]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\agarwalv\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "clf1 = RandomForestClassifier()\n",
    "clf4 = RandomForestClassifier()\n",
    "clf8 = RandomForestClassifier()\n",
    "clf1cbf = RandomForestClassifier()\n",
    "clf2 = RandomForestClassifier()\n",
    "clf2cbf = RandomForestClassifier()\n",
    "clf1.fit(train_1, target_1)\n",
    "clf1cbf.fit(train_1cbf, target_1cbf)\n",
    "clf2.fit(train_2, target_2)\n",
    "clf2cbf.fit(train_2cbf, target_2cbf)\n",
    "clf4.fit(train_4, target_4)\n",
    "clf8.fit(train_8, target_8)\n",
    "y_pred1 = clf1.predict(test_1)\n",
    "y_pred1cbf = clf1cbf.predict(test_1cbf)\n",
    "y_pred2 = clf2.predict(test_2)\n",
    "y_pred2cbf = clf2cbf.predict(test_2cbf)\n",
    "y_pred4 = clf4.predict(test_4)\n",
    "y_pred8 = clf8.predict(test_8)\n",
    "print(np.array(np.unique(y_pred1, return_counts=True)).T)\n",
    "print(np.array(np.unique(y_pred1cbf, return_counts=True)).T)\n",
    "print(np.array(np.unique(y_pred2, return_counts=True)).T)\n",
    "print(np.array(np.unique(y_pred2cbf, return_counts=True)).T)\n",
    "print(np.array(np.unique(y_pred4, return_counts=True)).T)\n",
    "print(np.array(np.unique(y_pred8, return_counts=True)).T)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\agarwalv\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "C:\\Users\\agarwalv\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "clf1 = SVC(kernel=\"poly\")\n",
    "clf4 = SVC(kernel=\"linear\")\n",
    "clf8 = SVC(kernel=\"linear\")\n",
    "clf1cbf = SVC(kernel=\"poly\")\n",
    "clf2 = SVC(kernel=\"linear\")\n",
    "clf2cbf = SVC(kernel=\"linear\")\n",
    "clf1.fit(train_1, target_1)\n",
    "clf1cbf.fit(train_1cbf, target_1cbf)\n",
    "clf2.fit(train_2, target_2)\n",
    "clf2cbf.fit(train_2cbf, target_2cbf)\n",
    "clf4.fit(train_4, target_4)\n",
    "clf8.fit(train_8, target_8)\n",
    "y_pred1 = clf1.predict(test_1)\n",
    "y_pred1cbf = clf1cbf.predict(test_1cbf)\n",
    "y_pred2 = clf2.predict(test_2)\n",
    "y_pred2cbf = clf2cbf.predict(test_2cbf)\n",
    "y_pred4 = clf4.predict(test_4)\n",
    "y_pred8 = clf8.predict(test_8)\n",
    "print(np.array(np.unique(y_pred1, return_counts=True)).T)\n",
    "print(np.array(np.unique(y_pred1cbf, return_counts=True)).T)\n",
    "print(np.array(np.unique(y_pred2, return_counts=True)).T)\n",
    "print(np.array(np.unique(y_pred2cbf, return_counts=True)).T)\n",
    "print(np.array(np.unique(y_pred4, return_counts=True)).T)\n",
    "print(np.array(np.unique(y_pred8, return_counts=True)).T)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[   0 5176]]\n",
      "[[   0 3029]]\n",
      "[[  0 940]]\n"
     ]
    }
   ],
   "source": [
    "clf1 = xgb.XGBClassifier(objective=\"binary:logistic\", learning_rate = 0.15)\n",
    "clf4 = xgb.XGBClassifier(objective=\"binary:logistic\", learning_rate = 0.08)\n",
    "clf8 = xgb.XGBClassifier(objective=\"binary:logistic\", learning_rate = 0.05)\n",
    "test_1 = test_1.values\n",
    "test_4 = test_4.values\n",
    "test_8 = test_8.values\n",
    "clf1.fit(train_1, target_1)\n",
    "clf4.fit(train_4, target_4)\n",
    "clf8.fit(train_8, target_8)\n",
    "y_pred1 = clf1.predict(test_1)\n",
    "y_pred4 = clf4.predict(test_4)\n",
    "y_pred8 = clf8.predict(test_8)\n",
    "print(np.array(np.unique(y_pred1, return_counts=True)).T)\n",
    "print(np.array(np.unique(y_pred4, return_counts=True)).T)\n",
    "print(np.array(np.unique(y_pred8, return_counts=True)).T)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- abstract_char_count\n",
    "- rec_processing_time\n",
    "- query_char_count\n",
    "- user_os\n",
    "- clicks\n",
    "- session_id"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_1 = pd.DataFrame(y_pred1, index=test_1.index)\n",
    "pred_1cbf = pd.DataFrame(y_pred1cbf, index=test_1cbf.index)\n",
    "pred_2 = pd.DataFrame(y_pred2, index=test_2.index)\n",
    "pred_2cbf = pd.DataFrame(y_pred2cbf, index=test_2cbf.index)\n",
    "pred_4 = pd.DataFrame(y_pred4, index=test_4.index)\n",
    "pred_8 = pd.DataFrame(y_pred8, index=test_8.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = pred_1.append(pred_1cbf.append(pred_2.append(pred_2cbf))).rename(columns={0:\"set_clicked\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pred = pred_1.append(pred_4.append(pred_8)).rename(columns={0:\"set_clicked\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "submit = pd.read_csv(\"tcdml1920-rec-click-pred--submission file.csv\", index_col= 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    9071\n",
       "1      74\n",
       "Name: set_clicked, dtype: int64"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred[\"set_clicked\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "submit.to_csv(r\"prediction.csv\", index = True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
