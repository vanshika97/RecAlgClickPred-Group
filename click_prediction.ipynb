{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python: 3.7.3 (default, Apr 24 2019, 15:29:51) [MSC v.1915 64 bit (AMD64)]\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import math\n",
    "import sklearn\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import xgboost as xgb\n",
    "from time import time\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import linear_model\n",
    "%config IPcompletor.greedy = True\n",
    "from sklearn.svm import LinearSVC, SVC\n",
    "print(\"Python: {}\".format(sys.version))\n",
    "from imblearn.over_sampling import SMOTE, SVMSMOTE, ADASYN\n",
    "from imblearn.under_sampling import NearMiss\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import f1_score, confusion_matrix, mean_squared_error,recall_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\vansh\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3057: DtypeWarning: Columns (4,5,34) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    }
   ],
   "source": [
    "train_set = pd.read_csv(\"tcdml1920-rec-click-pred--training.csv\", index_col = 0,error_bad_lines=True)#385688\n",
    "test_set = pd.read_csv(\"tcdml1920-rec-click-pred--test.csv\", index_col = 0,error_bad_lines=False)#9146\n",
    "test_set.dropna(how=\"all\", inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NULL values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set.replace([\"\\\\N\", \"nA\", \"Not provided\", \"*unknown*\"], np.nan, inplace=True)\n",
    "test_set.replace([\"\\\\N\", \"nA\", \"Not provided\", \"*unknown*\"], np.nan, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = train_set[(train_set[\"set_clicked\"] == 1) | (train_set.time_recs_viewed.notnull())]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = temp.drop(columns = [\"time_recs_viewed\", \"document_language_provided\", \"year_published\",\"number_of_authors\"])\n",
    "test_set = test_set.drop(columns = [\"time_recs_viewed\", \"document_language_provided\", \"year_published\",\"number_of_authors\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in temp.select_dtypes(include=['object']):\n",
    "    target = temp.groupby(i)[\"set_clicked\"].agg(pd.Series.mean)\n",
    "    temp[i] = temp[i].map(target)\n",
    "    test_set[i] = test_set[i].map(target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp[temp.columns]=temp[temp.columns].fillna(temp.mean().iloc[0])\n",
    "target = temp.pop(\"set_clicked\")\n",
    "test_set[test_set.columns]=test_set[test_set.columns].fillna(test_set.mean().iloc[0])\n",
    "pp= test_set.pop(\"set_clicked\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\agarwalv\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "C:\\Users\\agarwalv\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\agarwalv\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[   0 9065]\n",
      " [   1   80]]\n",
      "[[   0 9145]]\n",
      "[[   0 9131]\n",
      " [   1   14]]\n",
      "[[   1 9145]]\n"
     ]
    }
   ],
   "source": [
    "model1 = RandomForestClassifier()\n",
    "model2 = LogisticRegression()\n",
    "model3 = SVC()\n",
    "model4 = DecisionTreeClassifier()\n",
    "\n",
    "model1.fit(temp, target)\n",
    "model2.fit(temp, target)\n",
    "model3.fit(temp, target)\n",
    "model4.fit(temp, target)\n",
    "\n",
    "y_pred1 = model1.predict(test_set)\n",
    "y_pred2 = model2.predict(test_set)\n",
    "y_pred3 = model3.predict(test_set)\n",
    "y_pred4 = model4.predict(test_set)\n",
    "\n",
    "print(np.array(np.unique(y_pred1, return_counts=True)).T)\n",
    "print(np.array(np.unique(y_pred2, return_counts=True)).T)\n",
    "print(np.array(np.unique(y_pred3, return_counts=True)).T)\n",
    "print(np.array(np.unique(y_pred4, return_counts=True)).T)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Approach 2\n",
    "   - Divide datasets based on *Organisaton_id*\n",
    "   - Further divide into *content_based_filtering* and non *cbf*s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_1cbf = train_set[(train_set.organization_id == 1) & (train_set.algorithm_class == 'content_based_filtering')]\n",
    "train_1 = train_set[(train_set.organization_id == 1) & (train_set.algorithm_class != 'content_based_filtering')]\n",
    "train_2cbf = train_set[(train_set.organization_id != 1) & (train_set.algorithm_class == 'content_based_filtering')]\n",
    "train_2 = train_set[(train_set.organization_id != 1) & (train_set.algorithm_class != 'content_based_filtering')]\n",
    "train_4 = train_set[train_set.organization_id == 4]\n",
    "train_8 = train_set[train_set.organization_id == 8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_1cbf = test_set[(test_set.organization_id == 1) & (test_set.algorithm_class == 'content_based_filtering')]\n",
    "test_1 = test_set[(test_set.organization_id == 1) & (test_set.algorithm_class != 'content_based_filtering')]\n",
    "test_2cbf = test_set[(test_set.organization_id != 1) & (test_set.algorithm_class == 'content_based_filtering')]\n",
    "test_2 = test_set[(test_set.organization_id != 1) & (test_set.algorithm_class != 'content_based_filtering')]\n",
    "test_4 = test_set[test_set.organization_id == 4]\n",
    "test_8 = test_set[test_set.organization_id == 8]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "   - Keep columns based on statistical tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_1cbf = train_1cbf[[\"app_lang\",\"query_detected_language\", \"query_document_id\", \"cbf_parser\", \"timezone_by_ip\", \"country_by_ip\",\"app_version\", \"local_hour_of_request\", \"recommendation_algorithm_id_used\", \"set_clicked\"]]\n",
    "train_1 = train_1[[\"algorithm_class\", \"app_lang\", \"timezone_by_ip\", \"country_by_ip\",\"app_version\", \"local_hour_of_request\", \"recommendation_algorithm_id_used\", \"set_clicked\"]]\n",
    "train_2 = train_2[[\"query_detected_language\", \"query_document_id\", \"app_lang\", \"timezone_by_ip\", \"local_hour_of_request\", \"recommendation_algorithm_id_used\", \"item_type\", \"set_clicked\"]]\n",
    "train_2cbf = train_2cbf[[ \"country_by_ip\",\"cbf_parser\", \"recommendation_algorithm_id_used\", \"item_type\", \"set_clicked\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_1cbf = test_1cbf[[\"app_lang\",\"query_detected_language\", \"query_document_id\", \"cbf_parser\", \"timezone_by_ip\", \"country_by_ip\",\"app_version\", \"local_hour_of_request\", \"recommendation_algorithm_id_used\", \"set_clicked\"]]\n",
    "test_1 = test_1[[\"algorithm_class\", \"app_lang\", \"timezone_by_ip\", \"country_by_ip\",\"app_version\", \"local_hour_of_request\", \"recommendation_algorithm_id_used\", \"set_clicked\"]]\n",
    "test_2 = test_2[[\"query_detected_language\", \"query_document_id\", \"app_lang\", \"timezone_by_ip\", \"local_hour_of_request\", \"recommendation_algorithm_id_used\", \"item_type\", \"set_clicked\"]]\n",
    "test_2cbf = test_2cbf[[ \"country_by_ip\",\"cbf_parser\", \"recommendation_algorithm_id_used\", \"item_type\", \"set_clicked\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "   - Remove columns having > 40% NULL values "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\vansh\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \"\"\"\n",
      "C:\\Users\\vansh\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "train_1.dropna(thresh= train_1.shape[0]*0.4, axis=1, inplace = True)\n",
    "train_2.dropna(thresh= train_2.shape[0]*0.4, axis=1, inplace = True)\n",
    "train_1cbf.dropna(thresh= train_1cbf.shape[0]*0.4, axis=1, inplace = True)\n",
    "train_2cbf.dropna(thresh= train_2cbf.shape[0]*0.4, axis=1, inplace = True)\n",
    "train_4.dropna(thresh= train_4.shape[0]*0.4, axis=1, inplace = True)\n",
    "train_8.dropna(thresh= train_8.shape[0]*0.4, axis=1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_1 = test_1[list(train_1.columns)]\n",
    "test_2 = test_2[list(train_2.columns)]\n",
    "test_1cbf = test_1cbf[list(train_1cbf.columns)]\n",
    "test_2cbf = test_2cbf[list(train_2cbf.columns)]\n",
    "test_4 = test_4[list(train_4.columns)]\n",
    "test_8 = test_8[list(train_8.columns)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Fill NULLS with mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\vansh\\Anaconda3\\lib\\site-packages\\pandas\\core\\frame.py:3391: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self[k1] = value[k2]\n"
     ]
    }
   ],
   "source": [
    "train_1[train_1.columns]=train_1[train_1.columns].fillna(train_1.mode().iloc[0])\n",
    "train_2[train_2.columns]=train_2[train_2.columns].fillna(train_2.mode().iloc[0])\n",
    "train_1cbf[train_1cbf.columns]=train_1cbf[train_1cbf.columns].fillna(train_1cbf.mode().iloc[0])\n",
    "train_2cbf[train_2cbf.columns]=train_2cbf[train_2cbf.columns].fillna(train_2cbf.mode().iloc[0])\n",
    "train_4[train_4.columns]=train_4[train_4.columns].fillna(train_4.mode().iloc[0])\n",
    "train_8[train_8.columns]=train_8[train_8.columns].fillna(train_8.mode().iloc[0])\n",
    "test_1[test_1.columns]=test_1[test_1.columns].fillna(train_1.mode().iloc[0])\n",
    "test_1cbf[test_1cbf.columns]=test_1cbf[test_1cbf.columns].fillna(train_1cbf.mode().iloc[0])\n",
    "test_2[test_2.columns]=test_2[test_2.columns].fillna(train_2.mode().iloc[0])\n",
    "test_2cbf[test_2cbf.columns]=test_2cbf[test_2cbf.columns].fillna(train_2cbf.mode().iloc[0])\n",
    "test_4[test_4.columns]=test_4[test_4.columns].fillna(train_4.mode().iloc[0])\n",
    "test_8[test_8.columns]=test_8[test_8.columns].fillna(train_8.mode().iloc[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_cols_8 = [\"abstract_word_count\",\"query_word_count\",\"query_char_count\",\"query_document_id\",\"abstract_char_count\",\"hour_request_received\",\"local_hour_of_request\",\"recommendation_algorithm_id_used\",\"clicks\"]\n",
    "numeric_cols_4 = [\"query_word_count\",\"query_char_count\",\"hour_request_received\",\"recommendation_algorithm_id_used\",\"clicks\"]\n",
    "numeric_cols_1 = [\"local_hour_of_request\",\"recommendation_algorithm_id_used\"]\n",
    "numeric_cols_1cbf = [\"local_hour_of_request\",\"recommendation_algorithm_id_used\"]\n",
    "numeric_cols_2 = [\"query_document_id\", \"local_hour_of_request\",\"recommendation_algorithm_id_used\"]\n",
    "numeric_cols_2cbf = [\"recommendation_algorithm_id_used\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### To Numeric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\vansh\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \"\"\"\n",
      "C:\\Users\\vansh\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "for i in numeric_cols_1:\n",
    "    train_1[i] = pd.to_numeric(train_1[i], errors='coerce')\n",
    "    test_1[i] = pd.to_numeric(test_1[i], errors='coerce')\n",
    "for i in numeric_cols_4:\n",
    "    train_4[i] = pd.to_numeric(train_4[i], errors='coerce')\n",
    "    test_4[i] = pd.to_numeric(test_4[i], errors='coerce')\n",
    "for i in numeric_cols_8:\n",
    "    train_8[i] = pd.to_numeric(train_8[i], errors='coerce')\n",
    "    test_8[i] = pd.to_numeric(test_8[i], errors='coerce')\n",
    "for i in numeric_cols_1cbf:\n",
    "    train_1cbf[i] = pd.to_numeric(train_1cbf[i], errors='coerce')\n",
    "    test_1cbf[i] = pd.to_numeric(test_1cbf[i], errors='coerce')\n",
    "for i in numeric_cols_2:\n",
    "    train_2[i] = pd.to_numeric(train_2[i], errors='coerce')\n",
    "    test_2[i] = pd.to_numeric(test_2[i], errors='coerce')\n",
    "for i in numeric_cols_2cbf:\n",
    "    train_2cbf[i] = pd.to_numeric(train_2cbf[i], errors='coerce')\n",
    "    test_2cbf[i] = pd.to_numeric(test_2cbf[i], errors='coerce')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_1.index = test_1.index.astype(\"int\")\n",
    "test_1cbf.index = test_1cbf.index.astype(\"int\")\n",
    "test_2.index = test_2.index.astype(\"int\")\n",
    "test_2cbf.index = test_2cbf.index.astype(\"int\")\n",
    "test_4.index = test_4.index.astype(\"int\")\n",
    "test_8.index = test_8.index.astype(\"int\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Encoding\n",
    "- ~One hot~\n",
    "- Target\n",
    "- ~Label~"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_1.dropna(how=\"all\", inplace = True)\n",
    "test_1cbf.dropna(how=\"all\", inplace = True)\n",
    "test_2.dropna(how=\"all\", inplace = True)\n",
    "test_2cbf.dropna(how=\"all\", inplace = True)\n",
    "test_4.dropna(how=\"all\", inplace = True)\n",
    "test_8.dropna(how=\"all\", inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\vansh\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:20: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "C:\\Users\\vansh\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:24: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    }
   ],
   "source": [
    "for i in train_1.select_dtypes(include=['object']):\n",
    "    target = train_1.groupby(i)[\"set_clicked\"].agg(pd.Series.mean)\n",
    "    train_1[i] = train_1[i].map(target)\n",
    "    test_1[i] = test_1[i].map(target)\n",
    "for i in train_1cbf.select_dtypes(include=['object']):\n",
    "    target = train_1cbf.groupby(i)[\"set_clicked\"].agg(pd.Series.mean)\n",
    "    train_1cbf[i] = train_1cbf[i].map(target)\n",
    "    test_1cbf[i] = test_1cbf[i].map(target)\n",
    "for i in train_2.select_dtypes(include=['object']):\n",
    "    target = train_2.groupby(i)[\"set_clicked\"].agg(pd.Series.mean)\n",
    "    train_2[i] = train_2[i].map(target)\n",
    "    test_2[i] = test_2[i].map(target)\n",
    "for i in train_2cbf.select_dtypes(include=['object']):\n",
    "    target = train_2cbf.groupby(i)[\"set_clicked\"].agg(pd.Series.mean)\n",
    "    train_2cbf[i] = train_2cbf[i].map(target)\n",
    "    test_2cbf[i] = test_2cbf[i].map(target)\n",
    "\n",
    "for i in train_4.select_dtypes(include=['object']):\n",
    "    target = train_4.groupby(i)[\"set_clicked\"].agg(pd.Series.mean)\n",
    "    train_4[i] = train_4[i].map(target)\n",
    "    test_4[i] = test_4[i].map(target)\n",
    "for i in train_8.select_dtypes(include=['object']):\n",
    "    target = train_8.groupby(i)[\"set_clicked\"].agg(pd.Series.mean)\n",
    "    train_8[i] = train_8[i].map(target)\n",
    "    test_8[i] = test_8[i].map(target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_1[test_1.columns]=test_1[test_1.columns].fillna(test_1.mean().iloc[0])\n",
    "test_1cbf[test_1cbf.columns]=test_1cbf[test_1cbf.columns].fillna(test_1cbf.mean().iloc[0])\n",
    "test_2[test_2.columns]=test_2[test_2.columns].fillna(test_2.mean().iloc[0])\n",
    "test_2cbf[test_2cbf.columns]=test_2cbf[test_2cbf.columns].fillna(test_2cbf.mean().iloc[0])\n",
    "test_4[test_4.columns]=test_4[test_4.columns].fillna(test_4.mean().iloc[0])\n",
    "test_8[test_8.columns]=test_8[test_8.columns].fillna(test_8.mean().iloc[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Resampling datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils import resample\n",
    "train_1_0 = train_1[train_1[\"set_clicked\"]==0]\n",
    "train_1_1 = train_1[train_1[\"set_clicked\"]==1]\n",
    "train_1_0 = resample(train_1_0, replace=True, n_samples=len(train_1_1)*50)\n",
    "train_1 = pd.concat([train_1_0, train_1_1])\n",
    "\n",
    "train_1cbf_0 = train_1cbf[train_1cbf[\"set_clicked\"]==0]\n",
    "train_1cbf_1 = train_1cbf[train_1cbf[\"set_clicked\"]==1]\n",
    "train_1cbf_0 = resample(train_1cbf_0, replace=True, n_samples=len(train_1cbf_1)*50)\n",
    "train_1cbf = pd.concat([train_1cbf_0, train_1cbf_1])\n",
    "\n",
    "train_2_0 = train_2[train_2[\"set_clicked\"]==0]\n",
    "train_2_1 = train_2[train_2[\"set_clicked\"]==1]\n",
    "train_2_0 = resample(train_2_0, replace=True, n_samples=len(train_2_1)*50)\n",
    "train_2 = pd.concat([train_2_0, train_2_1])\n",
    "\n",
    "train_2cbf_0 = train_2cbf[train_2cbf[\"set_clicked\"]==0]\n",
    "train_2cbf_1 = train_2cbf[train_2cbf[\"set_clicked\"]==1]\n",
    "train_2cbf_0 = resample(train_2cbf_0, replace=True, n_samples=len(train_2cbf_1)*50)\n",
    "train_2cbf = pd.concat([train_2cbf_0, train_2cbf_1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Target: (69870,), Training: (69870, 7)\n",
      "Target: (212976,), Training: (212976, 8)\n",
      "Target: (16677,), Training: (16677, 7)\n",
      "Target: (45390,), Training: (45390, 4)\n",
      "Target: (100215,), Training: (100215, 33)\n",
      "Target: (15226,), Training: (15226, 30)\n"
     ]
    }
   ],
   "source": [
    "target_1 = train_1.pop(\"set_clicked\")\n",
    "test_1.drop(columns=[\"set_clicked\"], inplace =True)\n",
    "print(\"Target: {}, Training: {}\".format(target_1.shape, train_1.shape))\n",
    "target_1cbf = train_1cbf.pop(\"set_clicked\")\n",
    "test_1cbf.drop(columns=[\"set_clicked\"], inplace =True)\n",
    "print(\"Target: {}, Training: {}\".format(target_1cbf.shape, train_1cbf.shape))\n",
    "target_2 = train_2.pop(\"set_clicked\")\n",
    "test_2.drop(columns=[\"set_clicked\"], inplace =True)\n",
    "print(\"Target: {}, Training: {}\".format(target_2.shape, train_2.shape))\n",
    "target_2cbf = train_2cbf.pop(\"set_clicked\")\n",
    "test_2cbf.drop(columns=[\"set_clicked\"], inplace =True)\n",
    "print(\"Target: {}, Training: {}\".format(target_2cbf.shape, train_2cbf.shape))\n",
    "target_4 = train_4.pop(\"set_clicked\")\n",
    "test_4.drop(columns=[\"set_clicked\"], inplace =True)\n",
    "print(\"Target: {}, Training: {}\".format(target_4.shape, train_4.shape))\n",
    "target_8 = train_8.pop(\"set_clicked\")\n",
    "test_8.drop(columns=[\"set_clicked\"], inplace =True)\n",
    "print(\"Target: {}, Training: {}\".format(target_8.shape, train_8.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SMOTE\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "smt = SVMSMOTE()\n",
    "# train_1, target_1 = smt.fit_sample(train_1, target_1)\n",
    "train_4, target_4 = smt.fit_sample(train_4,target_4)\n",
    "train_8, target_8 = smt.fit_sample(train_8,target_8)\n",
    "\n",
    "smt = ADASYN()\n",
    "# train_1, target_1 = smt.fit_sample(train_1, target_1)\n",
    "train_4, target_4 = smt.fit_sample(train_4,target_4)\n",
    "train_8, target_8 = smt.fit_sample(train_8,target_8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NearMiss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "nr = NearMiss()\n",
    "# train_1, target_1 = nr.fit_sample(train_1, target_1)\n",
    "train_4, target_4 = nr.fit_sample(train_4,target_4)\n",
    "train_8, target_8 = nr.fit_sample(train_8,target_8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bagging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[   0 1366]\n",
      " [   1   13]]\n",
      "[[   0 3768]\n",
      " [   1   29]]\n",
      "[[   0 1298]\n",
      " [   1   10]]\n",
      "[[   0 2657]\n",
      " [   1    4]]\n",
      "[[   0 3029]]\n",
      "[[  0 940]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import BaggingClassifier\n",
    "clf1 = BaggingClassifier()\n",
    "clf4 = BaggingClassifier()\n",
    "clf8 = BaggingClassifier()\n",
    "clf1cbf = BaggingClassifier()\n",
    "clf2 = BaggingClassifier()\n",
    "clf2cbf = BaggingClassifier()\n",
    "clf1.fit(train_1, target_1)\n",
    "clf1cbf.fit(train_1cbf, target_1cbf)\n",
    "clf2.fit(train_2, target_2)\n",
    "clf2cbf.fit(train_2cbf, target_2cbf)\n",
    "clf4.fit(train_4, target_4)\n",
    "clf8.fit(train_8, target_8)\n",
    "y_pred1 = clf1.predict(test_1)\n",
    "y_pred1cbf = clf1cbf.predict(test_1cbf)\n",
    "y_pred2 = clf2.predict(test_2)\n",
    "y_pred2cbf = clf2cbf.predict(test_2cbf)\n",
    "y_pred4 = clf4.predict(test_4)\n",
    "y_pred8 = clf8.predict(test_8)\n",
    "print(np.array(np.unique(y_pred1, return_counts=True)).T)\n",
    "print(np.array(np.unique(y_pred1cbf, return_counts=True)).T)\n",
    "print(np.array(np.unique(y_pred2, return_counts=True)).T)\n",
    "print(np.array(np.unique(y_pred2cbf, return_counts=True)).T)\n",
    "print(np.array(np.unique(y_pred4, return_counts=True)).T)\n",
    "print(np.array(np.unique(y_pred8, return_counts=True)).T)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\vansh\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\vansh\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\vansh\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\vansh\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\vansh\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[   0 1379]]\n",
      "[[   0 3797]]\n",
      "[[   0 1308]]\n",
      "[[   0 2661]]\n",
      "[[   0 3029]]\n",
      "[[  0 940]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\vansh\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "clf1 = LogisticRegression()\n",
    "clf1cbf = LogisticRegression()\n",
    "clf2 = LogisticRegression()\n",
    "clf2cbf = LogisticRegression()\n",
    "clf4 = LogisticRegression()\n",
    "clf8 = LogisticRegression()\n",
    "clf1.fit(train_1, target_1)\n",
    "clf1cbf.fit(train_1cbf, target_1cbf)\n",
    "clf2.fit(train_2, target_2)\n",
    "clf2cbf.fit(train_2cbf, target_2cbf)\n",
    "clf4.fit(train_4, target_4)\n",
    "clf8.fit(train_8, target_8)\n",
    "y_pred1 = clf1.predict(test_1)\n",
    "y_pred1cbf = clf1cbf.predict(test_1cbf)\n",
    "y_pred2 = clf2.predict(test_2)\n",
    "y_pred2cbf = clf2cbf.predict(test_2cbf)\n",
    "y_pred4 = clf4.predict(test_4)\n",
    "y_pred8 = clf8.predict(test_8)\n",
    "print(np.array(np.unique(y_pred1, return_counts=True)).T)\n",
    "print(np.array(np.unique(y_pred1cbf, return_counts=True)).T)\n",
    "print(np.array(np.unique(y_pred2, return_counts=True)).T)\n",
    "print(np.array(np.unique(y_pred2cbf, return_counts=True)).T)\n",
    "print(np.array(np.unique(y_pred4, return_counts=True)).T)\n",
    "print(np.array(np.unique(y_pred8, return_counts=True)).T)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[   0 1366]\n",
      " [   1   13]]\n",
      "[[   0 3745]\n",
      " [   1   52]]\n",
      "[[   0 1264]\n",
      " [   1   44]]\n",
      "[[   0 2656]\n",
      " [   1    5]]\n",
      "[[   0 3029]]\n",
      "[[  0 940]]\n"
     ]
    }
   ],
   "source": [
    "clf1 = DecisionTreeClassifier()\n",
    "clf1cbf = DecisionTreeClassifier()\n",
    "clf2 = DecisionTreeClassifier()\n",
    "clf2cbf = DecisionTreeClassifier()\n",
    "clf4 = DecisionTreeClassifier()\n",
    "clf8 = DecisionTreeClassifier()\n",
    "clf1.fit(train_1, target_1)\n",
    "clf1cbf.fit(train_1cbf, target_1cbf)\n",
    "clf2.fit(train_2, target_2)\n",
    "clf2cbf.fit(train_2cbf, target_2cbf)\n",
    "clf4.fit(train_4, target_4)\n",
    "clf8.fit(train_8, target_8)\n",
    "y_pred1 = clf1.predict(test_1)\n",
    "y_pred1cbf = clf1cbf.predict(test_1cbf)\n",
    "y_pred2 = clf2.predict(test_2)\n",
    "y_pred2cbf = clf2cbf.predict(test_2cbf)\n",
    "y_pred4 = clf4.predict(test_4)\n",
    "y_pred8 = clf8.predict(test_8)\n",
    "print(np.array(np.unique(y_pred1, return_counts=True)).T)\n",
    "print(np.array(np.unique(y_pred1cbf, return_counts=True)).T)\n",
    "print(np.array(np.unique(y_pred2, return_counts=True)).T)\n",
    "print(np.array(np.unique(y_pred2cbf, return_counts=True)).T)\n",
    "print(np.array(np.unique(y_pred4, return_counts=True)).T)\n",
    "print(np.array(np.unique(y_pred8, return_counts=True)).T)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\vansh\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "C:\\Users\\vansh\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "C:\\Users\\vansh\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "C:\\Users\\vansh\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "C:\\Users\\vansh\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[   0 1367]\n",
      " [   1   12]]\n",
      "[[   0 3771]\n",
      " [   1   26]]\n",
      "[[   0 1300]\n",
      " [   1    8]]\n",
      "[[   0 2657]\n",
      " [   1    4]]\n",
      "[[   0 3029]]\n",
      "[[  0 940]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\vansh\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "clf1 = RandomForestClassifier()\n",
    "clf4 = RandomForestClassifier()\n",
    "clf8 = RandomForestClassifier()\n",
    "clf1cbf = RandomForestClassifier()\n",
    "clf2 = RandomForestClassifier()\n",
    "clf2cbf = RandomForestClassifier()\n",
    "clf1.fit(train_1, target_1)\n",
    "clf1cbf.fit(train_1cbf, target_1cbf)\n",
    "clf2.fit(train_2, target_2)\n",
    "clf2cbf.fit(train_2cbf, target_2cbf)\n",
    "clf4.fit(train_4, target_4)\n",
    "clf8.fit(train_8, target_8)\n",
    "y_pred1 = clf1.predict(test_1)\n",
    "y_pred1cbf = clf1cbf.predict(test_1cbf)\n",
    "y_pred2 = clf2.predict(test_2)\n",
    "y_pred2cbf = clf2cbf.predict(test_2cbf)\n",
    "y_pred4 = clf4.predict(test_4)\n",
    "y_pred8 = clf8.predict(test_8)\n",
    "print(np.array(np.unique(y_pred1, return_counts=True)).T)\n",
    "print(np.array(np.unique(y_pred1cbf, return_counts=True)).T)\n",
    "print(np.array(np.unique(y_pred2, return_counts=True)).T)\n",
    "print(np.array(np.unique(y_pred2cbf, return_counts=True)).T)\n",
    "print(np.array(np.unique(y_pred4, return_counts=True)).T)\n",
    "print(np.array(np.unique(y_pred8, return_counts=True)).T)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf1 = SVC(kernel=\"linear\")\n",
    "clf4 = SVC(kernel=\"linear\")\n",
    "clf8 = SVC(kernel=\"linear\")\n",
    "clf1cbf = SVC(kernel=\"linear\")\n",
    "clf2 = SVC(kernel=\"linear\")\n",
    "clf2cbf = SVC(kernel=\"linear\")\n",
    "clf1.fit(train_1, target_1)\n",
    "clf1cbf.fit(train_1cbf, target_1cbf)\n",
    "clf2.fit(train_2, target_2)\n",
    "clf2cbf.fit(train_2cbf, target_2cbf)\n",
    "clf4.fit(train_4, target_4)\n",
    "clf8.fit(train_8, target_8)\n",
    "y_pred1 = clf1.predict(test_1)\n",
    "y_pred1cbf = clf1cbf.predict(test_1cbf)\n",
    "y_pred2 = clf2.predict(test_2)\n",
    "y_pred2cbf = clf2cbf.predict(test_2cbf)\n",
    "y_pred4 = clf4.predict(test_4)\n",
    "y_pred8 = clf8.predict(test_8)\n",
    "print(np.array(np.unique(y_pred1, return_counts=True)).T)\n",
    "print(np.array(np.unique(y_pred1cbf, return_counts=True)).T)\n",
    "print(np.array(np.unique(y_pred2, return_counts=True)).T)\n",
    "print(np.array(np.unique(y_pred2cbf, return_counts=True)).T)\n",
    "print(np.array(np.unique(y_pred4, return_counts=True)).T)\n",
    "print(np.array(np.unique(y_pred8, return_counts=True)).T)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_1 = pd.DataFrame(y_pred1, index=test_1.index)\n",
    "pred_1cbf = pd.DataFrame(y_pred1cbf, index=test_1cbf.index)\n",
    "pred_2 = pd.DataFrame(y_pred2, index=test_2.index)\n",
    "pred_2cbf = pd.DataFrame(y_pred2cbf, index=test_2cbf.index)\n",
    "# pred_4 = pd.DataFrame(y_pred4, index=test_4.index)\n",
    "# pred_8 = pd.DataFrame(y_pred8, index=test_8.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = pred_1.append(pred_1cbf.append(pred_2.append(pred_2cbf))).rename(columns={0:\"set_clicked\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred.index = pred.index.astype(\"int\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>set_clicked</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>recommendation_set_id</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>47517</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49712</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54992</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64077</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66547</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       set_clicked\n",
       "recommendation_set_id             \n",
       "47517                            0\n",
       "49712                            0\n",
       "54992                            0\n",
       "64077                            0\n",
       "66547                            0"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "submit = pd.read_csv(\"tcdml1920-rec-click-pred--submission file.csv\", index_col= 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [],
   "source": [
    "submit[\"set_clicked\"] = y_pred1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    9095\n",
       "1      50\n",
       "Name: set_clicked, dtype: int64"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred[\"set_clicked\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred.to_csv(r\"prediction1.csv\", index = True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
